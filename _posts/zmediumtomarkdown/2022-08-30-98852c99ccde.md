---
title: "【Python】來喝一碗爬蟲湯 — Beautiful Soup網頁解析！"
author: "Martin"
date: 2022-08-30T08:47:38.643+0000
last_modified_at: 2022-08-30T08:47:38.643+0000
categories: ""
tags: []
description: "早在進公司的第一個月，就寫出人生第一隻爬蟲，當時就有稍微用到Beautiful Soup這個Python的套件，但當時沒好好深入了解，導致３個月後又要使用時，又要再查一次文件orz，果然還是第一次學的時候，乖乖學扎實、寫文章做筆記，才不用之後每次要用都要回去查……"
image:
  path: /assets/98852c99ccde/1*nr3B5E2RIU0DzRE_rkMfig.png
render_with_liquid: false
---

### 【Python】來喝一碗爬蟲湯 — Beautiful Soup網頁解析！

早在進公司的第一個月，就寫出人生第一隻爬蟲，當時就有稍微用到Beautiful Soup這個Python的套件，但當時沒好好深入了解，導致３個月後又要使用時，又要再查一次文件orz，果然還是第一次學的時候，乖乖學扎實、寫文章做筆記，才不用之後每次要用都要回去查…
廢話不多說，開始煮湯囉～～～

首先當然是官方食譜（文件）上桌先：

[**Beautiful Soup Documentation \- Beautiful Soup 4\.9\.0 documentation**](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#){:target="_blank"} 
[_Beautiful Soup is a Python library for pulling data out of HTML and XML files\. It works with your favorite parser to…_ www\.crummy\.com](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#){:target="_blank"}

（官網還特別註明有其他語言的版本，中文只有簡體QQ）

**Beautiful Soup這個Python的套件主要是幫我們解析一份文件\(HTML、XML\)並從中抓取需要的資料。** 有這個概念以後就可以來邊用邊學囉～第一步當然是引用並且設定參數：
```
from bs4 import BeautifulSoup 
soup = BeautifulSoup(html_doc, 'html.parser')
```

第一個參數放的是要解析的文件，第二個則是要解析文件的parser，Beautiful Soup 支援Python 原生函式庫的HTML parser（也就是上面範例所使用的），也支援其他第三方的parser：


![[https://www\.crummy\.com/software/BeautifulSoup/bs4/doc/\#installing\-a\-parser](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser){:target="_blank"}](/assets/98852c99ccde/1*nr3B5E2RIU0DzRE_rkMfig.png)

[https://www\.crummy\.com/software/BeautifulSoup/bs4/doc/\#installing\-a\-parser](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser){:target="_blank"}

到此就算設定完參數的部分，下一步就可以去抓取需要的資料，以下都先假設HTML 為解析的文件，等之後有解析過XML 再來補充
#### HTML 標籤

抓取資料時可以直接使用HTML 的標籤：
```
soup.title
# <title>The Dormouse's story</title>
soup.title.string
# u'The Dormouse's story'
```
#### CSS selector

除了直接用HTML 標籤外，有時網頁會有太多相同標籤，此時就需要用css selector 的方式來抓取特定資料：
```
tag: 
soup.select("p > a")
# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
id: 
soup.select("#link1")
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]
class: 
soup.select(".sister")
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
```

更詳細的用法可參考 [這裡](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors){:target="_blank"}

從 `class` 這例子看到不只回傳一個符合的項目，此時可以注意到 `select` 這用法。

`select` 會從文件中找出所有符合條件的項目，用起來其實就跟 `find_all` 一樣；若只要符合條件的第一個項目的話，則可以使用 `find` 或是 `select_one`

除了剛講到的 `select` 跟 `find_all` 之外，還有像是 `find_parents()` 、 `find_next_siblings()` 、 `find_previous_siblings()` 、 `find_all_previous()` 、 `find_all_next()` 等不同方法可以直接找到特定標籤附近的標籤

更詳細的用法可參考 [這裡](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-parents-and-find-parent){:target="_blank"}

終於找到特定標籤後，我們常常是需要標籤內的text 或是其他屬性，此時也有一些方法可以處理：
```
attribute:
soup.find('a').get('href')
# http://example.com/elsie
```

[更多用法](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#going-down){:target="_blank"}

參考資料：


[![](https://i.imgur.com/KoCvRk9.png)](https://ithelp.ithome.com.tw/articles/10196817){:target="_blank"}



[![](https://i.imgur.com/lWwjf3Q.png)](https://ithelp.ithome.com.tw/articles/10204390){:target="_blank"}


[**Beautiful Soup Documentation \- Beautiful Soup 4\.9\.0 documentation**](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#){:target="_blank"} 
[_Beautiful Soup is a Python library for pulling data out of HTML and XML files\. It works with your favorite parser to…_ www\.crummy\.com](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#){:target="_blank"}



_[Post](https://medium.com/@martin87713/python-%E4%BE%86%E5%96%9D%E4%B8%80%E7%A2%97%E7%88%AC%E8%9F%B2%E6%B9%AF-beautiful-soup%E7%B6%B2%E9%A0%81%E8%A7%A3%E6%9E%90-98852c99ccde){:target="_blank"} converted from Medium by [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"}._
